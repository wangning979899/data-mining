{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:/weka/Dataset/Real estate valuation data set.xlsx\")\n",
    "df = pd.DataFrame(df)\n",
    "df = df.drop(['No'],axis=1)\n",
    "df = np.array(df)\n",
    "splitted_array = np.split(df,[-1],axis=1)\n",
    "data = pd.DataFrame(splitted_array[0])\n",
    "label = pd.DataFrame(splitted_array[1])\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataset into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                105       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 643\n",
      "Trainable params: 643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/300\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 1659.7000\n",
      "Epoch 2/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 1657.0239\n",
      "Epoch 3/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 1654.8140\n",
      "Epoch 4/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 1652.6684\n",
      "Epoch 5/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 1650.5966\n",
      "Epoch 6/300\n",
      "310/310 [==============================] - 0s 61us/step - loss: 1648.5990\n",
      "Epoch 7/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1646.5855\n",
      "Epoch 8/300\n",
      "310/310 [==============================] - 0s 61us/step - loss: 1644.4873\n",
      "Epoch 9/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 1642.2214\n",
      "Epoch 10/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 1639.7939\n",
      "Epoch 11/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1637.1947\n",
      "Epoch 12/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 1634.3176\n",
      "Epoch 13/300\n",
      "310/310 [==============================] - 0s 61us/step - loss: 1631.0664\n",
      "Epoch 14/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 1627.3069\n",
      "Epoch 15/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 1622.9094\n",
      "Epoch 16/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 1617.8176\n",
      "Epoch 17/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 1611.8998\n",
      "Epoch 18/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 1604.9896\n",
      "Epoch 19/300\n",
      "310/310 [==============================] - 0s 64us/step - loss: 1596.6808\n",
      "Epoch 20/300\n",
      "310/310 [==============================] - 0s 74us/step - loss: 1586.7943\n",
      "Epoch 21/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 1574.9145\n",
      "Epoch 22/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 1560.5486\n",
      "Epoch 23/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 1543.2968\n",
      "Epoch 24/300\n",
      "310/310 [==============================] - 0s 64us/step - loss: 1522.5391\n",
      "Epoch 25/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1497.7299\n",
      "Epoch 26/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1468.4939\n",
      "Epoch 27/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 1433.6720\n",
      "Epoch 28/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1392.7538\n",
      "Epoch 29/300\n",
      "310/310 [==============================] - 0s 61us/step - loss: 1345.2345\n",
      "Epoch 30/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 1290.7486\n",
      "Epoch 31/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1228.4594\n",
      "Epoch 32/300\n",
      "310/310 [==============================] - 0s 61us/step - loss: 1158.8573\n",
      "Epoch 33/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 1081.5964\n",
      "Epoch 34/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 995.5019\n",
      "Epoch 35/300\n",
      "310/310 [==============================] - 0s 64us/step - loss: 902.6169\n",
      "Epoch 36/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 804.4669\n",
      "Epoch 37/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 704.4994\n",
      "Epoch 38/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 604.6709\n",
      "Epoch 39/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 507.4158\n",
      "Epoch 40/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 415.9865\n",
      "Epoch 41/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 335.0270\n",
      "Epoch 42/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 267.3452\n",
      "Epoch 43/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 215.6325\n",
      "Epoch 44/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 178.2386\n",
      "Epoch 45/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 154.8499\n",
      "Epoch 46/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 142.5093\n",
      "Epoch 47/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 136.6023\n",
      "Epoch 48/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 134.3821\n",
      "Epoch 49/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 133.5975\n",
      "Epoch 50/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 132.9346\n",
      "Epoch 51/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 131.7561\n",
      "Epoch 52/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 130.2527\n",
      "Epoch 53/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 128.1511\n",
      "Epoch 54/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 126.1935\n",
      "Epoch 55/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 124.6094\n",
      "Epoch 56/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 123.0803\n",
      "Epoch 57/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 121.6766\n",
      "Epoch 58/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 120.3827\n",
      "Epoch 59/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 119.3696\n",
      "Epoch 60/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 118.1137\n",
      "Epoch 61/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 117.1183\n",
      "Epoch 62/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 116.0214\n",
      "Epoch 63/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 115.0150\n",
      "Epoch 64/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 114.0690\n",
      "Epoch 65/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 113.1349\n",
      "Epoch 66/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 112.2554\n",
      "Epoch 67/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 111.3672\n",
      "Epoch 68/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 110.6031\n",
      "Epoch 69/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 109.7043\n",
      "Epoch 70/300\n",
      "310/310 [==============================] - ETA: 0s - loss: 115.138 - 0s 45us/step - loss: 108.9122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 108.1139\n",
      "Epoch 72/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 107.4286\n",
      "Epoch 73/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 106.7145\n",
      "Epoch 74/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 105.8429\n",
      "Epoch 75/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 105.1202\n",
      "Epoch 76/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 104.5130\n",
      "Epoch 77/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 103.7984\n",
      "Epoch 78/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 103.1451\n",
      "Epoch 79/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 102.4887\n",
      "Epoch 80/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 101.8722\n",
      "Epoch 81/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 101.2936\n",
      "Epoch 82/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 100.6902\n",
      "Epoch 83/300\n",
      "310/310 [==============================] - 0s 58us/step - loss: 100.1117\n",
      "Epoch 84/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 99.5633\n",
      "Epoch 85/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 99.0601\n",
      "Epoch 86/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 98.5021\n",
      "Epoch 87/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 98.0585\n",
      "Epoch 88/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 97.5997\n",
      "Epoch 89/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 97.0304\n",
      "Epoch 90/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 96.6228\n",
      "Epoch 91/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 96.1700\n",
      "Epoch 92/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 95.6830\n",
      "Epoch 93/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 95.2544\n",
      "Epoch 94/300\n",
      "310/310 [==============================] - ETA: 0s - loss: 77.29 - 0s 45us/step - loss: 94.8312\n",
      "Epoch 95/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 94.4974\n",
      "Epoch 96/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 94.3001\n",
      "Epoch 97/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 93.7791\n",
      "Epoch 98/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 93.3129\n",
      "Epoch 99/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 92.9103\n",
      "Epoch 100/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 92.5495\n",
      "Epoch 101/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 92.2486\n",
      "Epoch 102/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 91.7969\n",
      "Epoch 103/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 91.4666\n",
      "Epoch 104/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 91.1401\n",
      "Epoch 105/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 90.8241\n",
      "Epoch 106/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 90.4693\n",
      "Epoch 107/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 90.1538\n",
      "Epoch 108/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 89.8667\n",
      "Epoch 109/300\n",
      "310/310 [==============================] - 0s 51us/step - loss: 89.6791\n",
      "Epoch 110/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 89.2953\n",
      "Epoch 111/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 89.0132\n",
      "Epoch 112/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 88.7797\n",
      "Epoch 113/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 88.4908\n",
      "Epoch 114/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 88.2985\n",
      "Epoch 115/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 87.9350\n",
      "Epoch 116/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 87.7135\n",
      "Epoch 117/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 87.4267\n",
      "Epoch 118/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 87.1740\n",
      "Epoch 119/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 87.1621\n",
      "Epoch 120/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 86.7729\n",
      "Epoch 121/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 86.4589\n",
      "Epoch 122/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 86.1984\n",
      "Epoch 123/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 85.9761\n",
      "Epoch 124/300\n",
      "310/310 [==============================] - ETA: 0s - loss: 95.24 - 0s 39us/step - loss: 85.7486\n",
      "Epoch 125/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 85.5362\n",
      "Epoch 126/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 85.3399\n",
      "Epoch 127/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 85.2270\n",
      "Epoch 128/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 84.9453\n",
      "Epoch 129/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 84.8701\n",
      "Epoch 130/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 84.6084\n",
      "Epoch 131/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 84.6506\n",
      "Epoch 132/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 84.3977\n",
      "Epoch 133/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 84.1039\n",
      "Epoch 134/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 83.9710\n",
      "Epoch 135/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 83.7640\n",
      "Epoch 136/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 83.7251\n",
      "Epoch 137/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 83.4806\n",
      "Epoch 138/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 83.4327\n",
      "Epoch 139/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 83.2434\n",
      "Epoch 140/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 83.1899\n",
      "Epoch 141/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 83.0207\n",
      "Epoch 142/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 82.8705\n",
      "Epoch 143/300\n",
      "310/310 [==============================] - 0s 29us/step - loss: 82.6631\n",
      "Epoch 144/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 82.6008\n",
      "Epoch 145/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 82.5574\n",
      "Epoch 146/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 82.5007\n",
      "Epoch 147/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 82.2992\n",
      "Epoch 148/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 82.1561\n",
      "Epoch 149/300\n",
      "310/310 [==============================] - 0s 29us/step - loss: 82.0037\n",
      "Epoch 150/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 81.8690\n",
      "Epoch 151/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 81.7307\n",
      "Epoch 152/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 81.6268\n",
      "Epoch 153/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 81.5783\n",
      "Epoch 154/300\n",
      "310/310 [==============================] - 0s 74us/step - loss: 81.4891\n",
      "Epoch 155/300\n",
      "310/310 [==============================] - 0s 55us/step - loss: 81.3934\n",
      "Epoch 156/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 81.4234\n",
      "Epoch 157/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 81.2192\n",
      "Epoch 158/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 81.1412\n",
      "Epoch 159/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 80.9984\n",
      "Epoch 160/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 80.8895\n",
      "Epoch 161/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 80.8091\n",
      "Epoch 162/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 80.7066\n",
      "Epoch 163/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 80.6584\n",
      "Epoch 164/300\n",
      "310/310 [==============================] - ETA: 0s - loss: 86.69 - 0s 35us/step - loss: 80.5688\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 35us/step - loss: 80.5658\n",
      "Epoch 166/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 80.4740\n",
      "Epoch 167/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 80.3523\n",
      "Epoch 168/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 80.2707\n",
      "Epoch 169/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 80.2881\n",
      "Epoch 170/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 80.0862\n",
      "Epoch 171/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 80.0266\n",
      "Epoch 172/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 80.1943\n",
      "Epoch 173/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 79.9376\n",
      "Epoch 174/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 79.9010\n",
      "Epoch 175/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 79.7864\n",
      "Epoch 176/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 79.6391\n",
      "Epoch 177/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 79.6081\n",
      "Epoch 178/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 79.5062\n",
      "Epoch 179/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 79.4308\n",
      "Epoch 180/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 79.4936\n",
      "Epoch 181/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 79.3806\n",
      "Epoch 182/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 79.2899\n",
      "Epoch 183/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 79.2831\n",
      "Epoch 184/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 79.2065\n",
      "Epoch 185/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 79.1327\n",
      "Epoch 186/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 78.9886\n",
      "Epoch 187/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 78.8758\n",
      "Epoch 188/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 78.8225\n",
      "Epoch 189/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.8815\n",
      "Epoch 190/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.8084\n",
      "Epoch 191/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.6606\n",
      "Epoch 192/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.5701\n",
      "Epoch 193/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.5912\n",
      "Epoch 194/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 78.4182\n",
      "Epoch 195/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 78.3233\n",
      "Epoch 196/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 78.3117\n",
      "Epoch 197/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 78.2464\n",
      "Epoch 198/300\n",
      "310/310 [==============================] - 0s 29us/step - loss: 78.4214\n",
      "Epoch 199/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 78.2310\n",
      "Epoch 200/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 78.1047\n",
      "Epoch 201/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.9605\n",
      "Epoch 202/300\n",
      "310/310 [==============================] - 0s 29us/step - loss: 78.1505\n",
      "Epoch 203/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.9042\n",
      "Epoch 204/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.8009\n",
      "Epoch 205/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 77.8351\n",
      "Epoch 206/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.6778\n",
      "Epoch 207/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.5882\n",
      "Epoch 208/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 77.5061\n",
      "Epoch 209/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.4378\n",
      "Epoch 210/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.8655\n",
      "Epoch 211/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.6163\n",
      "Epoch 212/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.3893\n",
      "Epoch 213/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.2693\n",
      "Epoch 214/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.1842\n",
      "Epoch 215/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 77.1252\n",
      "Epoch 216/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.0125\n",
      "Epoch 217/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 76.9589\n",
      "Epoch 218/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 76.8731\n",
      "Epoch 219/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.1223\n",
      "Epoch 220/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.8295\n",
      "Epoch 221/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 76.7424\n",
      "Epoch 222/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.9569\n",
      "Epoch 223/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 77.0197\n",
      "Epoch 224/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.5963\n",
      "Epoch 225/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.4876\n",
      "Epoch 226/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 76.3628\n",
      "Epoch 227/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.3176\n",
      "Epoch 228/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.2484\n",
      "Epoch 229/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 76.1631\n",
      "Epoch 230/300\n",
      "310/310 [==============================] - 0s 29us/step - loss: 76.1245\n",
      "Epoch 231/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 76.0143\n",
      "Epoch 232/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.9027\n",
      "Epoch 233/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 75.8436\n",
      "Epoch 234/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.8125\n",
      "Epoch 235/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.7100\n",
      "Epoch 236/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 75.6585\n",
      "Epoch 237/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 75.5573\n",
      "Epoch 238/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.5157\n",
      "Epoch 239/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.4208\n",
      "Epoch 240/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.3647\n",
      "Epoch 241/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.3305\n",
      "Epoch 242/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 75.3048\n",
      "Epoch 243/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 75.2931\n",
      "Epoch 244/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 75.0672\n",
      "Epoch 245/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 75.2184\n",
      "Epoch 246/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 75.0538\n",
      "Epoch 247/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.8829\n",
      "Epoch 248/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.8447\n",
      "Epoch 249/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.8839\n",
      "Epoch 250/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.7320\n",
      "Epoch 251/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.6058\n",
      "Epoch 252/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.5758\n",
      "Epoch 253/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.5541\n",
      "Epoch 254/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.4847\n",
      "Epoch 255/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.5632\n",
      "Epoch 256/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.3580\n",
      "Epoch 257/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 74.6621\n",
      "Epoch 258/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.5357\n",
      "Epoch 259/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 74.2482\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 35us/step - loss: 74.3013\n",
      "Epoch 261/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.1416\n",
      "Epoch 262/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 74.0479\n",
      "Epoch 263/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.0162\n",
      "Epoch 264/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 74.1742\n",
      "Epoch 265/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.8999\n",
      "Epoch 266/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.7889\n",
      "Epoch 267/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 73.7780\n",
      "Epoch 268/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 73.8250\n",
      "Epoch 269/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.7796\n",
      "Epoch 270/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 73.6369\n",
      "Epoch 271/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 73.5961\n",
      "Epoch 272/300\n",
      "310/310 [==============================] - 0s 42us/step - loss: 73.5277\n",
      "Epoch 273/300\n",
      "310/310 [==============================] - 0s 48us/step - loss: 73.5813\n",
      "Epoch 274/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.4577\n",
      "Epoch 275/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 73.4243\n",
      "Epoch 276/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.5355\n",
      "Epoch 277/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 73.4340\n",
      "Epoch 278/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.2750\n",
      "Epoch 279/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.2088\n",
      "Epoch 280/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.2691\n",
      "Epoch 281/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 73.2320\n",
      "Epoch 282/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.1438\n",
      "Epoch 283/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.0439\n",
      "Epoch 284/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 73.0023\n",
      "Epoch 285/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 72.9668\n",
      "Epoch 286/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.0835\n",
      "Epoch 287/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 73.0351\n",
      "Epoch 288/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 72.9735\n",
      "Epoch 289/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 72.8619\n",
      "Epoch 290/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 72.7714\n",
      "Epoch 291/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 72.7558\n",
      "Epoch 292/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 72.8959\n",
      "Epoch 293/300\n",
      "310/310 [==============================] - 0s 45us/step - loss: 72.8556\n",
      "Epoch 294/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 72.6963\n",
      "Epoch 295/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 72.7740\n",
      "Epoch 296/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 72.7239\n",
      "Epoch 297/300\n",
      "310/310 [==============================] - 0s 32us/step - loss: 72.8495\n",
      "Epoch 298/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 72.5009\n",
      "Epoch 299/300\n",
      "310/310 [==============================] - 0s 39us/step - loss: 72.4261\n",
      "Epoch 300/300\n",
      "310/310 [==============================] - 0s 35us/step - loss: 72.4054\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(Dense(units = 6,use_bias = True,activation='relu',input_shape=(X_train.shape[1],) ))\n",
    "model.add(Dense(units = 15,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 15,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 15,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 1,activation='linear'))\n",
    "print(model.summary())\n",
    "model.compile(loss='mse',optimizer='nadam')\n",
    "history = model.fit(X_train, y_train,epochs=300,batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph for convergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7199975272147885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pre = model.predict(X_train)\n",
    "mean_absolute_error(y_train, Y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9247280469307535"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.3481062137038"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, Y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.18108182229304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
